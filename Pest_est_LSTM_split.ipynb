{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05526fc2",
   "metadata": {},
   "source": [
    "## Environment & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a800ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "#!wget http://prdownloads.sourceforge.net/ta-lib/ta-lib-0.4.0-src.tar.gz\n",
    "#!tar -xzvf ta-lib-0.4.0-src.tar.gz\n",
    "#%cd ta-lib\n",
    "#!./configure --prefix=/usr\n",
    "#!make\n",
    "#!make install\n",
    "#!pip install Ta-Lib\n",
    "!pip install XlsxWriter\n",
    "! pip install ipdb -q\n",
    "\n",
    "import ipdb\n",
    "import xlsxwriter\n",
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import datetime as datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7936827f",
   "metadata": {},
   "source": [
    "## Configuration & Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d489ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import talib\n",
    "#!pip install yfinance --upgrade --no-cache-dir\n",
    "#import requests\n",
    "#import yfinance as yf\n",
    "import warnings\n",
    "from scipy.stats import zscore\n",
    "\n",
    "from google.colab import files\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn import metrics\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "def training(mem, drpout, r_drpout, i_shp1, i_shp2, out):\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(mem, dropout=drpout, recurrent_dropout=r_drpout,input_shape=(i_shp1, i_shp2), activation='tanh'))\n",
    "        model.add(Dense(out))\n",
    "        model.compile(loss='mae', optimizer='Adam', metrics=['accuracy'])\n",
    "        monitor = EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=5, verbose=0, mode='auto')\n",
    "        checkpointer = ModelCheckpoint(filepath=\"best_weights.hdf5\", verbose=1, save_best_only=True) # save best model\n",
    "        model.fit(train_X,train_y,validation_data=(test_X,test_y),callbacks=[monitor,checkpointer],verbose=0,epochs=1000)\n",
    "        model.load_weights('best_weights.hdf5') # load weights from best model\n",
    "        return model\n",
    "\n",
    "# Regression chart.\n",
    "def chart_regression(pred, y, sort=True):\n",
    "    t = pd.DataFrame({'pred': pred, 'y': y.flatten()})\n",
    "    if sort:\n",
    "        t.sort_values(by=['y'], inplace=True)\n",
    "    plt.plot(t['y'].tolist(), label='expected')\n",
    "    plt.plot(t['pred'].tolist(), label='prediction')\n",
    "    plt.ylabel('output')\n",
    "    plt.legend()\n",
    "    plt.figure(num=None, figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "    plt.show()\n",
    "\n",
    "path = \"/content/drive/My Drive/Danismanlik/Horizon/AI/Apple/dat_March_20a.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57614746",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3b3be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path, index_col=1)\n",
    "\n",
    "# NaN data checking\n",
    "n_nan_dat = pd.isna(df['temp_min']).sum() \n",
    "print(n_nan_dat)\n",
    "# 158 data points are missing in each label (temp_min, temp_max, temp_avg, humig_pctg_min, humid_pctg_max, humid_pctg_avg\n",
    "df['temp_min'].interpolate(inplace=True)\n",
    "df['temp_max'].interpolate(inplace=True)\n",
    "df['temp_avg'].interpolate(inplace=True)\n",
    "df['humig_pctg_min'].interpolate(inplace=True)\n",
    "df['humid_pctg_max'].interpolate(inplace=True)\n",
    "df['humid_pctg_avg'].interpolate(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58681b95",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b50403",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = df.values\n",
    "# specify columns to plot\n",
    "groups = [6, 11, 14, 15, 16]\n",
    "i = 1\n",
    "# plot each column\n",
    "plt.figure()\n",
    "for group in groups:\n",
    "\tplt.subplot(len(groups), 1, i)\n",
    "\tplt.plot(values[:, group])\n",
    "\tplt.title(df.columns[group], y=0.5, loc='right')\n",
    "\ti += 1\n",
    "plt.show()\n",
    "\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = pd.DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = pd.concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\t# https://machinelearningmastery.com/multivariate-time-series-forecasting-lstms-keras/\n",
    "\treturn agg\n",
    "\n",
    "#n_df = df[['calculated_egg', 'int_dd', 'temp_min', 'temp_max', 'humig_pctg_min', 'humid_pctg_max']]\n",
    "#n_df = df[['calculated_egg', 'temp_min', 'temp_max', 'humig_pctg_min', 'humid_pctg_max']]\n",
    "n_df = df[['calculated_egg', 'temp_min', 'temp_max']]\n",
    "values = n_df.values\n",
    "# ensure all data is float\n",
    "values = values.astype('float32')\n",
    "\n",
    "#datset=np.array(n_df)\n",
    "\n",
    "# first we need to normalize our dataset\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "\n",
    "look_back = 7*24\n",
    "# look_back = 1\n",
    "\n",
    "reframed = series_to_supervised(scaled, look_back, 1)\n",
    "\n",
    "# drop columns we don't want to predict\n",
    "reframed.drop(reframed.columns[reframed.shape[1]-n_df.shape[1]+1:reframed.shape[1]], axis=1, inplace=True)\n",
    "print(reframed.head())\n",
    "print(reframed.shape)\n",
    "\n",
    "# split into train and test sets\n",
    "values = reframed.values\n",
    "n_train_hours = 1 * 9 * 30 * 24\n",
    "train = values[:n_train_hours, :]\n",
    "test = values[n_train_hours:, :]\n",
    "# split into input and outputs\n",
    "train_X, train_y = train[:, :-1], train[:, -1]\n",
    "test_X, test_y = test[:, :-1], test[:, -1]\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    "\n",
    "model= training(100, 0, 0, train_X.shape[1], train_X.shape[2], 1)\n",
    "\n",
    "pred = model.predict(test_X)\n",
    "\n",
    "# Plot the chart\n",
    "chart_regression(pred.flatten(),test_y, sort=False)\n",
    "\n",
    "# grab some data\n",
    "#ts, tmp_avg, tmp_max, tmp_min, hm_avg, hm_max, hm_min = np.double(df.loc[:,('unix_time_stamp')]),np.double(df.loc[:,('temp_avg')]), np.double(df.loc[:,('temp_max')]), np.double(df.loc[:,('temp_min')]), np.double(df.loc[:,('humid_pctg_avg')]), np.double(df.loc[:,('humid_pctg_max')]), np.double(df.loc[:,('humig_pctg_min')])\n",
    "\n",
    "datset = np.array(n_df)\n",
    "\n",
    "# normalize the dataset\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "scaler = scaler.fit(n_df)\n",
    "dtset = scaler.transform(datset)\n",
    "tavg =scaler.inverse_transform(dtset)[:,1]      # check orginal values of temp_avg\n",
    "\n",
    "n_df.count()\n",
    "\n",
    "Jan17['temp_avg'].plot()\n",
    "\n",
    "Jan17=df.loc[(df['year_'] == 2017) & (df['month_'] == 1)]\n",
    "\n",
    "testY.shape\n",
    "\n",
    "df.count()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800d24c1",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90e8607",
   "metadata": {},
   "outputs": [],
   "source": [
    "        model.fit(train_X,train_y,validation_data=(test_X,test_y),callbacks=[monitor,checkpointer],verbose=0,epochs=1000)\n",
    "        model.load_weights('best_weights.hdf5') # load weights from best model\n",
    "        return model\n",
    "\n",
    "# Regression chart.\n",
    "def chart_regression(pred, y, sort=True):\n",
    "    t = pd.DataFrame({'pred': pred, 'y': y.flatten()})\n",
    "    if sort:\n",
    "        t.sort_values(by=['y'], inplace=True)\n",
    "    plt.plot(t['y'].tolist(), label='expected')\n",
    "    plt.plot(t['pred'].tolist(), label='prediction')\n",
    "    plt.ylabel('output')\n",
    "    plt.legend()\n",
    "    plt.figure(num=None, figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "    plt.show()\n",
    "\n",
    "path = \"/content/drive/My Drive/Danismanlik/Horizon/AI/Apple/dat_March_20a.csv\"\n",
    "df = pd.read_csv(path, index_col=1)\n",
    "\n",
    "# NaN data checking\n",
    "n_nan_dat = pd.isna(df['temp_min']).sum() \n",
    "print(n_nan_dat)\n",
    "# 158 data points are missing in each label (temp_min, temp_max, temp_avg, humig_pctg_min, humid_pctg_max, humid_pctg_avg\n",
    "df['temp_min'].interpolate(inplace=True)\n",
    "df['temp_max'].interpolate(inplace=True)\n",
    "df['temp_avg'].interpolate(inplace=True)\n",
    "df['humig_pctg_min'].interpolate(inplace=True)\n",
    "df['humid_pctg_max'].interpolate(inplace=True)\n",
    "df['humid_pctg_avg'].interpolate(inplace=True)\n",
    "values = df.values\n",
    "# specify columns to plot\n",
    "groups = [6, 11, 14, 15, 16]\n",
    "i = 1\n",
    "# plot each column\n",
    "plt.figure()\n",
    "for group in groups:\n",
    "\tplt.subplot(len(groups), 1, i)\n",
    "\tplt.plot(values[:, group])\n",
    "\tplt.title(df.columns[group], y=0.5, loc='right')\n",
    "\ti += 1\n",
    "plt.show()\n",
    "\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = pd.DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = pd.concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\t# https://machinelearningmastery.com/multivariate-time-series-forecasting-lstms-keras/\n",
    "\treturn agg\n",
    "\n",
    "#n_df = df[['calculated_egg', 'int_dd', 'temp_min', 'temp_max', 'humig_pctg_min', 'humid_pctg_max']]\n",
    "#n_df = df[['calculated_egg', 'temp_min', 'temp_max', 'humig_pctg_min', 'humid_pctg_max']]\n",
    "n_df = df[['calculated_egg', 'temp_min', 'temp_max']]\n",
    "values = n_df.values\n",
    "# ensure all data is float\n",
    "values = values.astype('float32')\n",
    "\n",
    "#datset=np.array(n_df)\n",
    "\n",
    "# first we need to normalize our dataset\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "\n",
    "look_back = 7*24\n",
    "# look_back = 1\n",
    "\n",
    "reframed = series_to_supervised(scaled, look_back, 1)\n",
    "\n",
    "# drop columns we don't want to predict\n",
    "reframed.drop(reframed.columns[reframed.shape[1]-n_df.shape[1]+1:reframed.shape[1]], axis=1, inplace=True)\n",
    "print(reframed.head())\n",
    "print(reframed.shape)\n",
    "\n",
    "# split into train and test sets\n",
    "values = reframed.values\n",
    "n_train_hours = 1 * 9 * 30 * 24\n",
    "train = values[:n_train_hours, :]\n",
    "test = values[n_train_hours:, :]\n",
    "# split into input and outputs\n",
    "train_X, train_y = train[:, :-1], train[:, -1]\n",
    "test_X, test_y = test[:, :-1], test[:, -1]\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    "\n",
    "model= training(100, 0, 0, train_X.shape[1], train_X.shape[2], 1)\n",
    "\n",
    "pred = model.predict(test_X)\n",
    "\n",
    "# Plot the chart\n",
    "chart_regression(pred.flatten(),test_y, sort=False)\n",
    "\n",
    "# grab some data\n",
    "#ts, tmp_avg, tmp_max, tmp_min, hm_avg, hm_max, hm_min = np.double(df.loc[:,('unix_time_stamp')]),np.double(df.loc[:,('temp_avg')]), np.double(df.loc[:,('temp_max')]), np.double(df.loc[:,('temp_min')]), np.double(df.loc[:,('humid_pctg_avg')]), np.double(df.loc[:,('humid_pctg_max')]), np.double(df.loc[:,('humig_pctg_min')])\n",
    "\n",
    "datset = np.array(n_df)\n",
    "\n",
    "# normalize the dataset\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "scaler = scaler.fit(n_df)\n",
    "dtset = scaler.transform(datset)\n",
    "tavg =scaler.inverse_transform(dtset)[:,1]      # check orginal values of temp_avg\n",
    "\n",
    "n_df.count()\n",
    "\n",
    "Jan17['temp_avg'].plot()\n",
    "\n",
    "Jan17=df.loc[(df['year_'] == 2017) & (df['month_'] == 1)]\n",
    "\n",
    "testY.shape\n",
    "\n",
    "df.count()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d9026d",
   "metadata": {},
   "source": [
    "## Prediction & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc32ea82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import datetime as datetime\n",
    "import numpy as np\n",
    "#import talib\n",
    "#!pip install yfinance --upgrade --no-cache-dir\n",
    "#import requests\n",
    "#import yfinance as yf\n",
    "import warnings\n",
    "from scipy.stats import zscore\n",
    "\n",
    "from google.colab import files\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn import metrics\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "def training(mem, drpout, r_drpout, i_shp1, i_shp2, out):\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(mem, dropout=drpout, recurrent_dropout=r_drpout,input_shape=(i_shp1, i_shp2), activation='tanh'))\n",
    "        model.add(Dense(out))\n",
    "        model.compile(loss='mae', optimizer='Adam', metrics=['accuracy'])\n",
    "        monitor = EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=5, verbose=0, mode='auto')\n",
    "        checkpointer = ModelCheckpoint(filepath=\"best_weights.hdf5\", verbose=1, save_best_only=True) # save best model\n",
    "        model.fit(train_X,train_y,validation_data=(test_X,test_y),callbacks=[monitor,checkpointer],verbose=0,epochs=1000)\n",
    "        model.load_weights('best_weights.hdf5') # load weights from best model\n",
    "        return model\n",
    "\n",
    "# Regression chart.\n",
    "def chart_regression(pred, y, sort=True):\n",
    "    t = pd.DataFrame({'pred': pred, 'y': y.flatten()})\n",
    "    if sort:\n",
    "        t.sort_values(by=['y'], inplace=True)\n",
    "    plt.plot(t['y'].tolist(), label='expected')\n",
    "    plt.plot(t['pred'].tolist(), label='prediction')\n",
    "    plt.ylabel('output')\n",
    "    plt.legend()\n",
    "    plt.figure(num=None, figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "    plt.show()\n",
    "\n",
    "path = \"/content/drive/My Drive/Danismanlik/Horizon/AI/Apple/dat_March_20a.csv\"\n",
    "df = pd.read_csv(path, index_col=1)\n",
    "\n",
    "# NaN data checking\n",
    "n_nan_dat = pd.isna(df['temp_min']).sum() \n",
    "print(n_nan_dat)\n",
    "# 158 data points are missing in each label (temp_min, temp_max, temp_avg, humig_pctg_min, humid_pctg_max, humid_pctg_avg\n",
    "df['temp_min'].interpolate(inplace=True)\n",
    "df['temp_max'].interpolate(inplace=True)\n",
    "df['temp_avg'].interpolate(inplace=True)\n",
    "df['humig_pctg_min'].interpolate(inplace=True)\n",
    "df['humid_pctg_max'].interpolate(inplace=True)\n",
    "df['humid_pctg_avg'].interpolate(inplace=True)\n",
    "values = df.values\n",
    "# specify columns to plot\n",
    "groups = [6, 11, 14, 15, 16]\n",
    "i = 1\n",
    "# plot each column\n",
    "plt.figure()\n",
    "for group in groups:\n",
    "\tplt.subplot(len(groups), 1, i)\n",
    "\tplt.plot(values[:, group])\n",
    "\tplt.title(df.columns[group], y=0.5, loc='right')\n",
    "\ti += 1\n",
    "plt.show()\n",
    "\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = pd.DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = pd.concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\t# https://machinelearningmastery.com/multivariate-time-series-forecasting-lstms-keras/\n",
    "\treturn agg\n",
    "\n",
    "#n_df = df[['calculated_egg', 'int_dd', 'temp_min', 'temp_max', 'humig_pctg_min', 'humid_pctg_max']]\n",
    "#n_df = df[['calculated_egg', 'temp_min', 'temp_max', 'humig_pctg_min', 'humid_pctg_max']]\n",
    "n_df = df[['calculated_egg', 'temp_min', 'temp_max']]\n",
    "values = n_df.values\n",
    "# ensure all data is float\n",
    "values = values.astype('float32')\n",
    "\n",
    "#datset=np.array(n_df)\n",
    "\n",
    "# first we need to normalize our dataset\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "\n",
    "look_back = 7*24\n",
    "# look_back = 1\n",
    "\n",
    "reframed = series_to_supervised(scaled, look_back, 1)\n",
    "\n",
    "# drop columns we don't want to predict\n",
    "reframed.drop(reframed.columns[reframed.shape[1]-n_df.shape[1]+1:reframed.shape[1]], axis=1, inplace=True)\n",
    "print(reframed.head())\n",
    "print(reframed.shape)\n",
    "\n",
    "# split into train and test sets\n",
    "values = reframed.values\n",
    "n_train_hours = 1 * 9 * 30 * 24\n",
    "train = values[:n_train_hours, :]\n",
    "test = values[n_train_hours:, :]\n",
    "# split into input and outputs\n",
    "train_X, train_y = train[:, :-1], train[:, -1]\n",
    "test_X, test_y = test[:, :-1], test[:, -1]\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    "\n",
    "model= training(100, 0, 0, train_X.shape[1], train_X.shape[2], 1)\n",
    "\n",
    "pred = model.predict(test_X)\n",
    "\n",
    "# Plot the chart\n",
    "chart_regression(pred.flatten(),test_y, sort=False)\n",
    "\n",
    "# grab some data\n",
    "#ts, tmp_avg, tmp_max, tmp_min, hm_avg, hm_max, hm_min = np.double(df.loc[:,('unix_time_stamp')]),np.double(df.loc[:,('temp_avg')]), np.double(df.loc[:,('temp_max')]), np.double(df.loc[:,('temp_min')]), np.double(df.loc[:,('humid_pctg_avg')]), np.double(df.loc[:,('humid_pctg_max')]), np.double(df.loc[:,('humig_pctg_min')])\n",
    "\n",
    "datset = np.array(n_df)\n",
    "\n",
    "# normalize the dataset\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "scaler = scaler.fit(n_df)\n",
    "dtset = scaler.transform(datset)\n",
    "tavg =scaler.inverse_transform(dtset)[:,1]      # check orginal values of temp_avg\n",
    "\n",
    "n_df.count()\n",
    "\n",
    "Jan17['temp_avg'].plot()\n",
    "\n",
    "Jan17=df.loc[(df['year_'] == 2017) & (df['month_'] == 1)]\n",
    "\n",
    "testY.shape\n",
    "\n",
    "df.count()\n",
    "\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
